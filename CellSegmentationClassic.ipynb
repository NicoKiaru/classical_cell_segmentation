{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ebed44-e509-4019-b005-588f128d133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Third-party specialized imports\n",
    "import tifffile\n",
    "\n",
    "# Scikit-image imports\n",
    "from skimage import data, filters, io\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import (\n",
    "    disk, \n",
    "    dilation, \n",
    "    remove_small_objects, \n",
    "    skeletonize\n",
    ")\n",
    "from skimage.segmentation import expand_labels, find_boundaries\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "import os\n",
    "\n",
    "# Detect if running in Binder or set manually\n",
    "IN_BINDER = os.environ.get('BINDER_SERVICE_HOST') is not None\n",
    "\n",
    "# Configuration flags\n",
    "USE_NAPARI = not IN_BINDER  # Automatically use matplotlib in Binder\n",
    "SHOW_IMAGES = True  # Set to False to skip all visualization\n",
    "\n",
    "# Initialize viewer variable\n",
    "viewer = None\n",
    "\n",
    "# Setup based on environment\n",
    "if USE_NAPARI and SHOW_IMAGES:\n",
    "    try:\n",
    "        import napari\n",
    "        # Only use %gui qt if not in Binder and in Jupyter\n",
    "        if not IN_BINDER:\n",
    "            get_ipython().run_line_magic('gui', 'qt')\n",
    "        viewer = napari.Viewer()\n",
    "        print(\"Using napari for visualization\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not initialize napari: {e}\")\n",
    "        print(\"Falling back to matplotlib\")\n",
    "        USE_NAPARI = False\n",
    "else:\n",
    "    print(\"Using matplotlib for visualization\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43969d-1a5b-4a0f-b27c-4599c6e4aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, name='Image', colormap='gray', contrast_limits=None):\n",
    "    \"\"\"\n",
    "    Display an image using either napari or matplotlib.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : numpy.ndarray\n",
    "        The image to display\n",
    "    name : str\n",
    "        Name/title for the image\n",
    "    colormap : str\n",
    "        Colormap to use ('gray', 'viridis', 'plasma', etc.)\n",
    "    contrast_limits : tuple or None\n",
    "        Optional (min, max) values for contrast adjustment\n",
    "    \"\"\"\n",
    "    if not SHOW_IMAGES:\n",
    "        return\n",
    "    \n",
    "    if USE_NAPARI and viewer is not None:\n",
    "        # Napari display\n",
    "        viewer.add_image(image, name=name, colormap=colormap, \n",
    "                        contrast_limits=contrast_limits)\n",
    "    else:\n",
    "        # Matplotlib display\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        vmin, vmax = contrast_limits if contrast_limits else (None, None)\n",
    "        plt.imshow(image, cmap=colormap, vmin=vmin, vmax=vmax)\n",
    "        plt.title(name)\n",
    "        plt.axis('off')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "def display_labels(labels, name='Labels'):\n",
    "    \"\"\"\n",
    "    Display a label image using either napari or matplotlib.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    labels : numpy.ndarray\n",
    "        The label image to display\n",
    "    name : str\n",
    "        Name/title for the labels\n",
    "    \"\"\"\n",
    "    if not SHOW_IMAGES:\n",
    "        return\n",
    "    \n",
    "    if USE_NAPARI and viewer is not None:\n",
    "        # Napari display\n",
    "        viewer.add_labels(labels, name=name)\n",
    "    else:\n",
    "        # Matplotlib display\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(labels, cmap='tab20', interpolation='nearest')\n",
    "        plt.title(name)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c19b4-6ab7-42e5-96cd-afc0b3e2b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All variable parameters are here\n",
    "input_file = 'data/yeast.tif'\n",
    "ground_truth_file = 'data/cellpose_truth.tif'\n",
    "show_images = True\n",
    "save_result = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d912c5-0e07-4e20-acfc-10b708ed73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = io.imread(input_file)\n",
    "plane_of_interest = image[1,:,:] # Extract second plane\n",
    "\n",
    "if show_images:\n",
    "    display_image(plane_of_interest, name='Original', colormap='gray')\n",
    "\n",
    "\n",
    "# Display cellpose results, considered ground truth\n",
    "cellpose_mask = io.imread('data/cellpose_mask.tif')\n",
    "\n",
    "if show_images:\n",
    "    display_labels(cellpose_mask, name=\"Cellpose Label Image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f4c48-dcb6-4ea7-8ea7-89a607fffbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create empty DataFrame with all columns\n",
    "columns = [\n",
    "    'blur_radius_for_normalisation',\n",
    "    'median_filter_size', \n",
    "    'threshold_bright_pixels',\n",
    "    'remove_objects_below_size',\n",
    "    'min_distance_bridge_cut',\n",
    "    'dilate_borders_px',\n",
    "    'remove_objects_above_size',\n",
    "    'label_expansion',\n",
    "    'IoU_Score',\n",
    "    'Ground_Truth_Objects',\n",
    "    'Detected_Objects'\n",
    "]\n",
    "\n",
    "results_table = pd.DataFrame(columns=columns)\n",
    "print(\"Results table initialized:\")\n",
    "\n",
    "from IPython.display import display\n",
    "display(results_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b634e-9242-4191-9a52-4d646d254431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis parameters\n",
    "\n",
    "# Pseudo flat field: we divide the image by its gaussian blurred version\n",
    "blur_radius_for_normalisation = 20\n",
    "\n",
    "# Removes noise from the image\n",
    "median_filter_size = 3\n",
    "\n",
    "# Threshold bright pixels which are surrounding the cell\n",
    "threshold_bright_pixels = 1.14 # 1.15 original\n",
    "\n",
    "# Remove small objects which are assumed not to represent any cell border\n",
    "remove_objects_below_size = 140 # 150 original\n",
    "\n",
    "# Splits seeds connected by a thin bridge\n",
    "min_distance_bridge_cut = 4\n",
    "\n",
    "# Dilate border mask. Goal: closing cells, without losing small ones. Value too big: small cell are missed. Values too small: cells remain opened, thus closed\n",
    "dilate_borders_px = 9 # original 10\n",
    "\n",
    "# Once the image is becoming a label image, we remove the labels which are too big: they are not cells but rather the background or interstices between cells\n",
    "remove_objects_above_size = 5000\n",
    "\n",
    "# Makes cells more blobby, make them match better their outline\n",
    "label_expansion = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22218e3-3fb7-4dfd-be65-ff9abbe4c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize: divide by the gaussian blurred version of the image (radius 20 pixels), output is 32 bits\n",
    "def normalize_with_blur(image, blur_radius):\n",
    "    \"\"\"\n",
    "    Normalize image by dividing by its Gaussian blurred version.\n",
    "    Returns 32-bit float result.\n",
    "    \"\"\"\n",
    "    # Gaussian blur\n",
    "    blurred = filters.gaussian(image.astype(np.float32), sigma=blur_radius)\n",
    "    \n",
    "    # Normalize and convert to 32-bit float\n",
    "    normalized = (image.astype(np.float32) / blurred).astype(np.float32)\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa164467-309f-47e9-8fa2-c6bebbd6115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_image = normalize_with_blur(plane_of_interest, blur_radius=blur_radius_for_normalisation)\n",
    "\n",
    "if show_images:\n",
    "    display_image(normalized_image, name='Normalized', colormap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77603266-7073-44ca-a6e8-c5a0c5efc783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply median filter\n",
    "filtered_image = filters.median(normalized_image, disk(median_filter_size))\n",
    "\n",
    "if show_images:\n",
    "    display_image(filtered_image, name='Median_Disk_3', colormap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff85e1db-0476-40d4-84e0-9d593fc57571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeps bright pixels surrounding cells\n",
    "thresholded_image = (filtered_image>threshold_bright_pixels)\n",
    "\n",
    "if show_images:\n",
    "    display_image(thresholded_image, name='Threshold_'+str(threshold_bright_pixels), colormap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cbdcbc-a53f-4efd-94cd-64e78aac2997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove small connected components, 8-bits connectivity\n",
    "cleaned_image = remove_small_objects(thresholded_image, min_size=remove_objects_below_size, connectivity=2)\n",
    "\n",
    "if show_images:\n",
    "    display_image(cleaned_image, name='Cleaned Objects below '+str(remove_objects_below_size), colormap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190a24f-8fe5-4629-af58-3aba6cb45de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilate border image\n",
    "\n",
    "dilated_image = dilation(cleaned_image, disk(dilate_borders_px))\n",
    "\n",
    "if show_images:\n",
    "    display_image(dilated_image, name='Dilated_'+str(dilate_borders_px), colormap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7aa283-35fd-4920-88f9-02a8c31af1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only objects SMALLER than a certain size\n",
    "def keep_small_objects(binary_mask, max_size):\n",
    "    # Remove objects >= max_size (keeping smaller ones)\n",
    "    large_objects = remove_small_objects(binary_mask, min_size=max_size)\n",
    "    # Subtract large objects from original to keep only small ones\n",
    "    small_objects_only = binary_mask & ~large_objects\n",
    "    return small_objects_only\n",
    "\n",
    "# Usage\n",
    "seeds_raw = keep_small_objects(~dilated_image, max_size=remove_objects_above_size)\n",
    "\n",
    "if show_images:\n",
    "    display_image(seeds_raw, name='Seeds', colormap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547810d9-66a6-4eb8-9c53-2ade1e007111",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def distance_threshold_mask(binary_mask, min_distance=2):\n",
    "    \"\"\"\n",
    "    Create a mask keeping only pixels that are at least min_distance \n",
    "    away from the edge of objects.\n",
    "    \"\"\"\n",
    "    # Compute distance transform (distance to nearest background pixel)\n",
    "    distance = ndimage.distance_transform_edt(binary_mask)\n",
    "    \n",
    "    # Keep only pixels with distance >= min_distance\n",
    "    thresholded_mask = distance >= min_distance\n",
    "    \n",
    "    return thresholded_mask\n",
    "\n",
    "seeds_split = distance_threshold_mask(seeds_raw, min_distance=min_distance_bridge_cut)\n",
    "\n",
    "if show_images:\n",
    "    display_image(seeds_split, name='Seeds Split', colormap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a3c05a-d497-49cf-b276-e6d7777e58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's invert and mark as label\n",
    "\n",
    "# Convert binary image to labeled image\n",
    "labels_raw = label(seeds_split)\n",
    "\n",
    "if show_images:\n",
    "    display_labels(labels_raw, name = \"Seeds Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7469d89-2b44-4a57-a93a-e61a9a15e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand labels to cover the whole cell\n",
    "labels = expand_labels(labels_raw, distance=label_expansion)\n",
    "\n",
    "if show_images:\n",
    "    # Find boundaries between labeled regions\n",
    "    display_labels(labels, name=\"Labels, Final\")\n",
    "\n",
    "if save_result:\n",
    "    # save results to tif\n",
    "    import tifffile\n",
    "    \n",
    "    # Save the labeled mask as TIFF\n",
    "    tifffile.imwrite('data/result_mask.tif', labels)\n",
    "\n",
    "if show_images:\n",
    "    # Find boundaries between labeled regions\n",
    "    boundaries = find_boundaries(labels, mode='thick')\n",
    "    \n",
    "    # Create a display image: labels with black boundaries\n",
    "    blobby_labels_eroded = labels.copy()\n",
    "    blobby_labels_eroded[boundaries] = 0  # Set boundaries to 0 (black)\n",
    "    \n",
    "    display_labels(boundaries, name=\"Cell Delimitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff94bd-59ad-43ca-a0a7-b05588f793a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def iou_binary(labels1, labels2):\n",
    "    \"\"\"Compute IoU between two label images (converted to binary).\"\"\"\n",
    "    # Convert to binary (any label > 0)\n",
    "    binary1 = labels1 > 0\n",
    "    binary2 = labels2 > 0\n",
    "    \n",
    "    # Compute intersection and union\n",
    "    intersection = np.sum(binary1 & binary2)\n",
    "    union = np.sum(binary1 | binary2)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if union == 0:\n",
    "        return 1.0 if intersection == 0 else 0.0\n",
    "    \n",
    "    iou = intersection / union\n",
    "    return iou\n",
    "\n",
    "# Usage\n",
    "iou_score = iou_binary(labels, cellpose_mask)\n",
    "print(f\"IoU: {iou_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968933c6-ed7f-409b-b37d-d25b7a17e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "iou_score = iou_binary(labels, cellpose_mask)\n",
    "n_gt_objects = len(np.unique(cellpose_mask)) - 1\n",
    "n_detected_objects = len(np.unique(labels)) - 1\n",
    "\n",
    "\n",
    "# Create new row with current parameters and results\n",
    "new_row = {\n",
    "    'blur_radius_for_normalisation': blur_radius_for_normalisation,\n",
    "    'median_filter_size': median_filter_size,\n",
    "    'threshold_bright_pixels': threshold_bright_pixels,\n",
    "    'remove_objects_below_size': remove_objects_below_size,\n",
    "    'min_distance_bridge_cut': min_distance_bridge_cut,\n",
    "    'dilate_borders_px': dilate_borders_px,\n",
    "    'remove_objects_above_size': remove_objects_above_size,\n",
    "    'label_expansion': label_expansion,\n",
    "    'IoU_Score': round(iou_score, 3),\n",
    "    'Ground_Truth_Objects': n_gt_objects,\n",
    "    'Detected_Objects': n_detected_objects\n",
    "}\n",
    "\n",
    "# Add to results table\n",
    "results_table = pd.concat([results_table, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "# Display updated table\n",
    "print(f\"Experiment {len(results_table)} added:\")\n",
    "display(results_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
